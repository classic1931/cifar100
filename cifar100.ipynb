{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzkYRDwDYqt5",
        "outputId": "61c29246-7354-461d-c0d0-4e35b1f4c1a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "(10000, 1)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import regularizers\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import models, layers, optimizers\n",
        "\n",
        "from keras import datasets\n",
        "\n",
        "# Dividing the cifar100 fine data into train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar100.load_data(label_mode='fine')\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Division: Divide the training dataset into two parts: a sub-\n",
        "training set and a validation set. Allocate randomly 1\n",
        "5 of the training dataset to\n",
        "serve as the validation set."
      ],
      "metadata": {
        "id": "9-8xkDNxe20O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_sub_train, X_val, y_sub_train, y_val = train_test_split(X_train, y_train, test_size=0.2, shuffle=True)\n",
        "# dividing the train data into sub train and validations 0.2 randomly"
      ],
      "metadata": {
        "id": "DVa0_Mxtery4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label Prediction Requirement: Ensure that your model is designed to predict the\n",
        "“fine” label (class) rather than the “coarse” label (superclass). Important: Your\n",
        "model must predict the “fine” label to be considered for grading; predicting the\n",
        "“coarse” label will result in a score of zero"
      ],
      "metadata": {
        "id": "gfhfxSkWGcj8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Selection: Using the sub-training and validation sets, identify\n",
        "the three most effective models\n",
        "\n"
      ],
      "metadata": {
        "id": "rJa_lfvHGpMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def AlexNet():\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(64, (3, 3), strides=(1,1), padding = 'same', activation='relu', input_shape=(32,32,3)),\n",
        "        #input shape 32x32x3 to match the dataset, 64 filter size was chosen to\n",
        "        #get an increased basic featurs, kept padding the same through out the\n",
        "        #model Stride 1x1 to get every pixel relu out performed with tanh and sigmoid\n",
        "        layers.Conv2D(192, (3, 3), padding = 'same', activation='relu', kernel_regularizer=regularizers.l2(1e-4)), #added L2 regularizers to improve overfitting\n",
        "        # increased filter to 192 enabled more complex features\n",
        "        layers.MaxPool2D(pool_size= (2,2), strides=(2,2)),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Conv2D(384, (3, 3), padding = 'same', activation='relu', kernel_regularizer=regularizers.l2(1e-4)),\n",
        "        layers.Conv2D(384, (3, 3), padding = 'same', activation='relu', kernel_regularizer=regularizers.l2(1e-4)),\n",
        "        layers.MaxPool2D(pool_size= (2,2), strides=(2,2)),\n",
        "        layers.Dropout(0.2), # added dropout to help wiht overfitting\n",
        "        layers.Flatten(), # flatten turn 2D feature map int 1D\n",
        "        layers.Dense(4096, activation='relu'),\n",
        "        layers.Dense(4096, activation='relu'),\n",
        "        layers.Dense(100, activation='softmax') # 100 for the multi class classification and softmax\n",
        "\n",
        "\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "lKuzeNwlGB9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmsprop_optimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-4)\n",
        "\n",
        "#adam_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "\n",
        "#sgd_optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
        "# three different optimizers i tried with RMSprop learning_rate=1e-4 being the best\n",
        "\n",
        "cnn_model1 = AlexNet()\n",
        "# I read sparse_categorical_crossentropy is best used in is best used for classification for reducing memory issue which i ran into\n",
        "cnn_model1.compile(loss='sparse_categorical_crossentropy', optimizer = rmsprop_optimizer, metrics=['accuracy'])\n",
        "#history = cnn_model1.fit(X_sub_train, y_sub_train, epochs=10, batch_size=64, validation_data=(X_val, y_val))\n",
        "history = cnn_model1.fit(X_train, y_train, epochs=10, batch_size=64)\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "M-xcDPmVS_I7",
        "outputId": "47161432-62dd-4b3b-e284-56a9df67d693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 50s 62ms/step - loss: 4.0853 - accuracy: 0.1485\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 48s 61ms/step - loss: 2.7123 - accuracy: 0.3386\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 48s 62ms/step - loss: 2.0180 - accuracy: 0.4920\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 48s 61ms/step - loss: 1.2807 - accuracy: 0.6646\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 48s 61ms/step - loss: 0.6489 - accuracy: 0.8296\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 48s 62ms/step - loss: 0.3651 - accuracy: 0.9107\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 48s 61ms/step - loss: 0.2685 - accuracy: 0.9395\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 48s 61ms/step - loss: 0.2218 - accuracy: 0.9541\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 48s 62ms/step - loss: 0.1897 - accuracy: 0.9631\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 48s 62ms/step - loss: 0.1667 - accuracy: 0.9710\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-00227d33541d>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val_accuracy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model1=cnn_model1.evaluate(X_test,y_test)\n",
        "cnn_model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oJn_GwwXjCW",
        "outputId": "f4975c00-1639-4dda-ac66-d056879ce56b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 9ms/step - loss: 4.2410 - accuracy: 0.4259\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_65 (Conv2D)          (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " conv2d_66 (Conv2D)          (None, 32, 32, 192)       110784    \n",
            "                                                                 \n",
            " max_pooling2d_29 (MaxPooli  (None, 16, 16, 192)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 16, 16, 192)       0         \n",
            "                                                                 \n",
            " conv2d_67 (Conv2D)          (None, 16, 16, 384)       663936    \n",
            "                                                                 \n",
            " conv2d_68 (Conv2D)          (None, 16, 16, 384)       1327488   \n",
            "                                                                 \n",
            " max_pooling2d_30 (MaxPooli  (None, 8, 8, 384)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_32 (Dropout)        (None, 8, 8, 384)         0         \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 24576)             0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 4096)              100667392 \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 100)               409700    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 119962404 (457.62 MB)\n",
            "Trainable params: 119962404 (457.62 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def vgg(): #vgg was used as a base structure for my second model\n",
        "            # it gave me great place to start with for focusing on filters\n",
        "    model = models.Sequential([ #filter sizes are similar to vgg, when testing i kept running into overfitting so i added L2 regularizers\n",
        "        layers.Conv2D(64, (3, 3), padding = 'same', activation='relu', kernel_regularizer=regularizers.l2(1e-4), input_shape=(32,32,3)),\n",
        "        layers.Conv2D(64, (3, 3), padding = 'same', activation='relu', kernel_regularizer=regularizers.l2(1e-4)),\n",
        "        layers.MaxPool2D(pool_size= (2,2), strides=(2,2)),\n",
        "        layers.Dropout(0.2), #added dropout at 0.2 to reduce overfitting and 0.2 was chosen becuase others performed worst\n",
        "        layers.Conv2D(128, (3, 3), padding = 'same', activation='relu', kernel_regularizer=regularizers.l2(1e-4)),\n",
        "        layers.Conv2D(128, (3, 3), padding = 'same', activation='relu', kernel_regularizer=regularizers.l2(1e-4)),\n",
        "        # using conv2d, conv2d, maxpool2d, dropout, i wanted to double to filters\n",
        "        # from 64, 128, 256, 512 to keep increasing network complex features\n",
        "        layers.MaxPool2D(pool_size= (2,2), strides=(2,2)),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Conv2D(256, (3, 3), padding = 'same', activation='relu', kernel_regularizer=regularizers.l2(1e-4)),\n",
        "        layers.Conv2D(256, (3, 3), padding = 'same', activation='relu', kernel_regularizer=regularizers.l2(1e-4)),\n",
        "        layers.Conv2D(256, (3, 3), padding = 'same', activation='relu', kernel_regularizer=regularizers.l2(1e-4)),\n",
        "        layers.MaxPool2D(pool_size= (2,2), strides=(2,2)),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Conv2D(512, (3, 3), padding = 'same', activation='relu', kernel_regularizer=regularizers.l2(1e-4)),\n",
        "        layers.Conv2D(512, (3, 3), padding = 'same', activation='relu', kernel_regularizer=regularizers.l2(1e-4)),\n",
        "        layers.Conv2D(512, (3, 3), padding = 'same', activation='relu', kernel_regularizer=regularizers.l2(1e-4)),\n",
        "        layers.MaxPool2D(pool_size= (2,2), strides=(2,2)),\n",
        "        layers.Dropout(0.2),\n",
        "        #add one more block but with tanh as an activation because i gained 2% in peformance\n",
        "        layers.Conv2D(512, (3, 3), padding = 'same', activation='tanh', kernel_regularizer=regularizers.l2(1e-4)),\n",
        "        layers.Conv2D(512, (3, 3), padding = 'same', activation='tanh', kernel_regularizer=regularizers.l2(1e-4)),\n",
        "        layers.Conv2D(512, (3, 3), padding = 'same', activation='tanh', kernel_regularizer=regularizers.l2(1e-4)),\n",
        "        layers.MaxPool2D(pool_size= (2,2), strides=(2,2)),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(4096, activation='relu'),\n",
        "        layers.Dense(4096, activation='relu'),\n",
        "        layers.Dense(100, activation='softmax')\n",
        "\n",
        "\n",
        "    ])\n",
        "    return model\n",
        "rmsprop_optimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-4)\n",
        "\n",
        "#adam_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "\n",
        "#sgd_optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
        "\n",
        "\n",
        "cnn_model2 = vgg()\n",
        "cnn_model2.compile(loss='sparse_categorical_crossentropy', optimizer = rmsprop_optimizer, metrics=['accuracy'])\n",
        "#history = cnn_model2.fit(X_sub_train, y_sub_train, epochs=10, batch_size=128, validation_data=(X_val, y_val))\n",
        "history = cnn_model2.fit(X_train, y_train, epochs=10, batch_size=128)\n",
        "test_model2=cnn_model2.evaluate(X_test,y_test)\n",
        "cnn_model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIKNtc1XbeJQ",
        "outputId": "b30259a1-96b4-4282-ed9c-f87c748c1052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "391/391 [==============================] - 32s 72ms/step - loss: 4.8109 - accuracy: 0.0221\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 26s 67ms/step - loss: 4.4395 - accuracy: 0.0584\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 26s 66ms/step - loss: 4.1760 - accuracy: 0.0985\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 26s 67ms/step - loss: 3.9236 - accuracy: 0.1438\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 26s 67ms/step - loss: 3.7134 - accuracy: 0.1760\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 26s 67ms/step - loss: 3.5408 - accuracy: 0.2080\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 26s 67ms/step - loss: 3.3671 - accuracy: 0.2414\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 26s 67ms/step - loss: 3.2219 - accuracy: 0.2699\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 26s 67ms/step - loss: 3.0724 - accuracy: 0.2966\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 26s 67ms/step - loss: 2.9302 - accuracy: 0.3246\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 2.9681 - accuracy: 0.3260\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_69 (Conv2D)          (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " conv2d_70 (Conv2D)          (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_31 (MaxPooli  (None, 16, 16, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_33 (Dropout)        (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_71 (Conv2D)          (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_72 (Conv2D)          (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_32 (MaxPooli  (None, 8, 8, 128)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_34 (Dropout)        (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_73 (Conv2D)          (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " conv2d_74 (Conv2D)          (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " conv2d_75 (Conv2D)          (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " max_pooling2d_33 (MaxPooli  (None, 4, 4, 256)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_35 (Dropout)        (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " conv2d_76 (Conv2D)          (None, 4, 4, 512)         1180160   \n",
            "                                                                 \n",
            " conv2d_77 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " conv2d_78 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " max_pooling2d_34 (MaxPooli  (None, 2, 2, 512)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_36 (Dropout)        (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " conv2d_79 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " conv2d_80 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " conv2d_81 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " max_pooling2d_35 (MaxPooli  (None, 1, 1, 512)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 4096)              2101248   \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 100)               409700    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34006948 (129.73 MB)\n",
            "Trainable params: 34006948 (129.73 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7bdK_CMGiTeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JGQFqIKLiTKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_model3(): # this model was created from what i learned from the previous two models\n",
        "                    # i noticed L2 regularizers decreased overfitting\n",
        "                    # adding BatchNormalization help with my issue of training plateaus\n",
        "                    # kept relu as the activation as it peformed best\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-4), input_shape=(32, 32, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(32, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-4), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Dropout(0.2),\n",
        "\n",
        "        layers.Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-4), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-4), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Dropout(0.2),\n",
        "\n",
        "        layers.Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-4), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-4), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Dropout(0.2),\n",
        "\n",
        "        layers.Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-4), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Dropout(0.2),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(512, kernel_regularizer=regularizers.l2(1e-4), activation='relu'),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(100, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "rmsprop_optimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-4)\n",
        "\n",
        "#adam_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "\n",
        "#sgd_optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
        "cnn_model3 = create_model3()\n",
        "cnn_model3.compile(loss='sparse_categorical_crossentropy', optimizer = rmsprop_optimizer, metrics=['accuracy'])\n",
        "#history = cnn_model3.fit(X_sub_train, y_sub_train, epochs=10, batch_size=128, validation_data=(X_val, y_val))\n",
        "history = cnn_model3.fit(X_train, y_train, epochs=10, batch_size=128)\n",
        "test_model3=cnn_model3.evaluate(X_test,y_test)\n",
        "cnn_model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcMoIqbmdYyb",
        "outputId": "56fa4223-90b9-40c9-a91a-cd8cabaf52d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "391/391 [==============================] - 17s 35ms/step - loss: 4.3940 - accuracy: 0.0794\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 3.7759 - accuracy: 0.1615\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 3.4500 - accuracy: 0.2138\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 3.1852 - accuracy: 0.2647\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 2.9723 - accuracy: 0.3008\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 2.7907 - accuracy: 0.3374\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 2.6294 - accuracy: 0.3671\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 2.4998 - accuracy: 0.3943\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 2.3822 - accuracy: 0.4216\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 2.2709 - accuracy: 0.4455\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 2.3846 - accuracy: 0.4364\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_82 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_14 (Ba  (None, 32, 32, 32)        128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_83 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_15 (Ba  (None, 32, 32, 32)        128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_36 (MaxPooli  (None, 16, 16, 32)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_38 (Dropout)        (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_84 (Conv2D)          (None, 16, 16, 128)       36992     \n",
            "                                                                 \n",
            " batch_normalization_16 (Ba  (None, 16, 16, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_85 (Conv2D)          (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_17 (Ba  (None, 16, 16, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_37 (MaxPooli  (None, 8, 8, 128)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_39 (Dropout)        (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_86 (Conv2D)          (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " batch_normalization_18 (Ba  (None, 8, 8, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_87 (Conv2D)          (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_19 (Ba  (None, 8, 8, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_38 (MaxPooli  (None, 4, 4, 256)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_40 (Dropout)        (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " conv2d_88 (Conv2D)          (None, 4, 4, 512)         1180160   \n",
            "                                                                 \n",
            " batch_normalization_20 (Ba  (None, 4, 4, 512)         2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_39 (MaxPooli  (None, 2, 2, 512)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_41 (Dropout)        (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 512)               1049088   \n",
            "                                                                 \n",
            " dropout_42 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 100)               51300     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3365892 (12.84 MB)\n",
            "Trainable params: 3363204 (12.83 MB)\n",
            "Non-trainable params: 2688 (10.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zOmfSeMMlpw0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}